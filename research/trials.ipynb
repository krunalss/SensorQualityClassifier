{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Runway\\\\Projects\\\\SensorQualityClassifier\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Runway\\\\Projects\\\\SensorQualityClassifier'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-4</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-8</th>\n",
       "      <th>Sensor-9</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-582</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "      <th>Sensor-590</th>\n",
       "      <th>Good/Bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wafer-501</td>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1517.0152</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4357</td>\n",
       "      <td>...</td>\n",
       "      <td>64.2405</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.0319</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>64.2405</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wafer-502</td>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>1397.5060</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>1.5527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>2.1266</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wafer-503</td>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>2.2296</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wafer-504</td>\n",
       "      <td>2997.28</td>\n",
       "      <td>2357.99</td>\n",
       "      <td>2141.0667</td>\n",
       "      <td>1236.5212</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>100</td>\n",
       "      <td>98.3344</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>1.5973</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4962</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1.7297</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wafer-505</td>\n",
       "      <td>3025.10</td>\n",
       "      <td>2475.18</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>1.5525</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.1927</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  Sensor-1  Sensor-2   Sensor-3   Sensor-4  Sensor-5  Sensor-6  \\\n",
       "0  Wafer-501   3076.81   2158.75  2208.2334  1517.0152    1.0980       100   \n",
       "1  Wafer-502   2951.62   2511.92  2253.5111  1397.5060    0.9660       100   \n",
       "2  Wafer-503   2930.42   2505.17  2235.0556  1302.6607    1.6347       100   \n",
       "3  Wafer-504   2997.28   2357.99  2141.0667  1236.5212    0.9698       100   \n",
       "4  Wafer-505   3025.10   2475.18  2235.0556  1302.6607    1.6347       100   \n",
       "\n",
       "   Sensor-7  Sensor-8  Sensor-9  ...  Sensor-582  Sensor-583  Sensor-584  \\\n",
       "0  110.1900    0.1247    1.4357  ...     64.2405      0.5016      0.0152   \n",
       "1  109.7611    0.1210    1.5527  ...      0.0000      0.4953      0.0105   \n",
       "2  109.9856    0.1230    1.4588  ...         NaN      0.4958      0.0111   \n",
       "3   98.3344    0.1238    1.5973  ...         NaN      0.4962      0.0086   \n",
       "4  109.9856    0.1230    1.5525  ...         NaN      0.4983      0.0159   \n",
       "\n",
       "   Sensor-585  Sensor-586  Sensor-587  Sensor-588  Sensor-589  Sensor-590  \\\n",
       "0      0.0040      3.0319      0.0465      0.0299      0.0090     64.2405   \n",
       "1      0.0037      2.1266     -0.0012      0.0252      0.0081      0.0000   \n",
       "2      0.0033      2.2296     -0.0012      0.0252      0.0081      0.0000   \n",
       "3      0.0024      1.7297     -0.0012      0.0252      0.0081      0.0000   \n",
       "4      0.0041      3.1927     -0.0012      0.0252      0.0081      0.0000   \n",
       "\n",
       "   Good/Bad  \n",
       "0        -1  \n",
       "1        -1  \n",
       "2        -1  \n",
       "3        -1  \n",
       "4        -1  \n",
       "\n",
       "[5 rows x 592 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('artifacts/training_data/Good_Data_Folder/wafer_07012020_041011.csv')\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, copy the existing column names to a list.\n",
    "new_columns = df.columns.tolist()\n",
    "#print(new_columns)\n",
    "\n",
    "# Then, replace the name of the first column (which might be an empty string or whatever placeholder pandas used).\n",
    "new_columns[0] = 'wafer_num'\n",
    "\n",
    "# Now, assign this list back to the DataFrame's columns attribute.\n",
    "df.columns = new_columns\n",
    "\n",
    "#covest uppercase to lowercase\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "\n",
    "# Convert all column names: replace '-' with '_' and convert to lowercase\n",
    "df.columns = [col.replace('-', '_').lower() for col in df.columns]\n",
    "\n",
    "# Convert all column names: replace '/' with '_' and convert to lowercase\n",
    "df.columns = [col.replace('/', '_').lower() for col in df.columns]\n",
    "\n",
    "\n",
    "# Now, if you view the first few rows of your DataFrame, the first column will have the name 'new_column_name'.\n",
    "#print(df.head())\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/104599\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "<hsfs.feature_store.FeatureStore object at 0x000001974D3E7400>\n"
     ]
    }
   ],
   "source": [
    "FS_API_KEY = \"\"\n",
    "FS_PROJECT_NAME = \"krunalss\"\n",
    "#project = hopsworks.login()\n",
    "project = hopsworks.login(\n",
    "        api_key_value=FS_API_KEY, project=FS_PROJECT_NAME\n",
    "    )\n",
    "fs = project.get_feature_store()\n",
    "print(fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wafer_fg = fs.get_or_create_feature_group(\n",
    "    name=\"wafer_project\",\n",
    "    version=1,\n",
    "    description=\"good_training_data\",\n",
    "    primary_key=[\"wafer_num\"],\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/104599/fs/104518/fg/541048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a3fea0d3c647158fd91d5858f8c9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/100 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: wafer_project_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/104599/jobs/named/wafer_project_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x1974d504340>, None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert data into feature group\n",
    "wafer_fg.insert(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: Please import `spmatrix` from the `scipy.sparse` namespace; the `scipy.sparse.base` namespace is deprecated and will be removed in SciPy 2.0.0.\n"
     ]
    }
   ],
   "source": [
    "import hsfs\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/104599\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "<hsfs.feature_store.FeatureStore object at 0x000002399DC39700>\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "FS_API_KEY = \"sdSk2pDkn0SMg3ek.blOTPiRhx7BParcWYOgh4zkuTlLksVU9OOp54LmZnFiEhIQ5TUXg2FHtmwH6tLql\"\n",
    "FS_PROJECT_NAME = \"krunalss\"\n",
    "#project = hopsworks.login()\n",
    "project = hopsworks.login(\n",
    "        api_key_value=FS_API_KEY, project=FS_PROJECT_NAME\n",
    "    )\n",
    "fs = project.get_feature_store()\n",
    "print(fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "connection = hsfs.connection()\n",
    "fs = connection.get_feature_store(name='krunalss_featurestore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the feature group\n",
    "feature_group = fs.get_feature_group('wafer_project', version=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a query to select all features from the feature group\n",
    "# Note: By not specifying specific features in select(), we get all features\n",
    "query = feature_group.select_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Could not establish connection to ArrowFlight Server. (Flight returned timeout error, with message: Deadline Exceeded) Will fall back to hive/spark for this session. If the error persists, you can disable using ArrowFlight by changing the cluster configuration (set 'enable_flyingduck'='false').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hive (13.00s) \n"
     ]
    }
   ],
   "source": [
    "# Read the query into a Pandas DataFrame\n",
    "feature_dataframe = query.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1537, 592)\n"
     ]
    }
   ],
   "source": [
    "print(feature_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_feature='good_bad'\n",
    "drop_non_contributing_feature='wafer_num'\n",
    "# Assuming you have one target variable you know the name of, e.g., 'target_feature'\n",
    "# Split the dataframe into features (X) and target (y)\n",
    "X = feature_dataframe.drop(target_feature, axis=1)  # Drop the target variable to isolate features\n",
    "X = feature_dataframe.drop(drop_non_contributing_feature, axis=1)\n",
    "y = feature_dataframe[target_feature]  # Isolate the target variable\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceed with your train-test split or any other data preparation steps\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(eval_metric='logloss', n_estimators=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an XGBoost classifier\n",
    "clf = xgb.XGBClassifier(objective='binary:logistic',  # Suitable for binary classification\n",
    "                            n_estimators=1, \n",
    "                            learning_rate=0.1, \n",
    "                            max_depth=3, \n",
    "                            eval_metric='logloss')  # Log loss for binary classification\n",
    "# Fit XGBoost classifier to the training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the training data using the trained classifier\n",
    "#y_pred_train = clf.predict(X_train)\n",
    "\n",
    "# Predict the test data using the trained classifier\n",
    "y_pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0: 1.0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = {\n",
    "                \"accuracy\" :accuracy_score(y_test, y_pred_test)\n",
    "        }\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for each fold: [1. 1. 1.]\n",
      "Mean CV Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Perform 3-fold cross-validation and compute the accuracy for each fold\n",
    "cv_scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
    "\n",
    "# Print the accuracy for each fold\n",
    "print(f\"Accuracy scores for each fold: {cv_scores}\")\n",
    "\n",
    "# Print the mean accuracy across all folds\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy of the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1_score': 1.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute f1 score\n",
    "metrics = {\n",
    "    \"f1_score\": f1_score(y_test, y_pred_test, average='macro')\n",
    "}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[435   0]\n",
      " [  0  27]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the confusion matrix for the test predictions\n",
    "results = confusion_matrix(y_test, y_pred_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the confusion matrix results\n",
    "df_cm = pd.DataFrame(\n",
    "    results, \n",
    "    ['True good', 'True bad'],\n",
    "    ['Pred good', 'Pred bad'],\n",
    ")\n",
    "\n",
    "# Create a heatmap using seaborn with annotations\n",
    "cm = sns.heatmap(df_cm, annot=True)\n",
    "\n",
    "# Get the figure and display it\n",
    "fig = cm.get_figure()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy of the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Schema\n",
    "The model needs to be set up with a Model Schema, which describes the inputs and outputs for a model.\n",
    "A Model Schema can be automatically generated from training examples, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema(type: 'tensor')\n",
      "Schema(type: 'columnar')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_schema': {'tensor_schema': {'shape': '(1075, 591)',\n",
       "   'type': 'float64'}},\n",
       " 'output_schema': {'columnar_schema': [{'name': 'good_bad', 'type': 'int64'}]}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "# Create a Schema for the input features using the values of X_train\n",
    "input_schema = Schema(X_train.values)\n",
    "print(input_schema)\n",
    "\n",
    "# Create a Schema for the output using y_train\n",
    "output_schema = Schema(y_train)\n",
    "print(output_schema)\n",
    "# Create a ModelSchema using the defined input and output schemas\n",
    "model_schema = ModelSchema(input_schema=input_schema, output_schema=output_schema)\n",
    "\n",
    "# Convert the model schema to a dictionary for inspection\n",
    "model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register model\n",
    "One of the features in Hopsworks is the model registry. This is where we can store different versions of models and compare their performance. Models from the registry can then be served as API endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory name for saving the model and related artifacts\n",
    "model_dir = \"sensor_quality_model\"\n",
    "\n",
    "# Check if the directory already exists; if not, create it\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "# Save the trained XGBoost classifier to a joblib file in the specified directory\n",
    "joblib.dump(clf, model_dir + '/xgboost_model.pkl')\n",
    "\n",
    "# Save the confusion matrix heatmap figure to an image file in the specified directory\n",
    "fig.savefig(model_dir + \"/confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7972a34a0bc48dd8a9090eed603fbe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7604733f2b9c4d32b41fab4214a60e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/16945 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f2e0217d804739a14ea2d5b30e3c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/38079 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e411aa1825204eca9861d386d7917e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/250 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/104599/models/sensor/1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'sensor', version: 1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the model registry\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "# Create a Python model named \"sensor\" in the model registry\n",
    "sensor_model = mr.python.create_model(\n",
    "    name=\"sensor\", \n",
    "    metrics=metrics,             # Specify the metrics used to evaluate the model\n",
    "    model_schema=model_schema,   # Use the previously defined model schema\n",
    "    # input_example=[4700702588013561],  # Provide an input example for testing deployments\n",
    "    description=\"detection of sensor's wafer condition whether it is good or bad\",  # Add a description for the model\n",
    ")\n",
    "\n",
    "# Save the model to the specified directory\n",
    "sensor_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
